---
name: Comprehensive CI/CD Pipeline

on:
  push: {}
  pull_request: {}
  schedule:
    - cron: '0 2 * * 1'  # Weekly on Monday at 2 AM UTC

permissions:
  contents: read
  issues: write
  pull-requests: write
  security-events: write

env:
  NODE_VERSION: '20'
  HOMEBREW_NO_AUTO_UPDATE: 1
  HOMEBREW_NO_INSTALL_CLEANUP: 1

jobs:
  # === Code Quality and Linting ===
  lint:
    name: Code Quality & Linting
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v5
      with:
        fetch-depth: 0  # Full history for better analysis
        submodules: recursive  # Initialize and update submodules

    - name: Setup Node.js
      uses: actions/setup-node@v5
      with:
        node-version: ${{ env.NODE_VERSION }}

    - name: Lint markdown files
      uses: DavidAnson/markdownlint-cli2-action@v20
      with:
        globs: |
          "**/*.md"
          "!external/**/*.md"
          "!stow/alacritty/.config/alacritty/catppuccin/**/*.md"
          "!stow/tmux/.tmux/plugins/**/*.md"

    - name: Lint shell scripts
      uses: ludeeus/action-shellcheck@master
      with:
        ignore_paths: >-
          ./external/**
          ./stow/bash/**
          ./stow/tmux/**
          ./stow/zsh/**

    - name: Lint YAML files
      uses: ibiqlik/action-yamllint@v3
      with:
        config_file: .yamllint.yml

    - name: Check for security issues
      run: |
        # Check for potential secrets (excluding common false positives)
        if grep -r -E "(password|secret|key|token)" --include="*.sh" --include="*.zsh" --exclude-dir=external . | \
           grep -v -E "(#.*|//.*|export.*=.*\$|bindkey|mode-keys|list-keys)" | \
           grep -v -E "(SSH.*key|API.*key.*=|password.*generator|completion)" | \
           grep -v -E "(work-secrets|\.key\$|\<key\>|_key=|function.*key|local.*key)" | \
           grep -E "=.*[\"'][^\"']*[\"']"; then
          echo "::warning::Potential secrets found in code"
        fi

        # Check for unsafe curl|sh practices (excluding documented examples with safety notes)
        temp_file=$(mktemp)
        grep -r -B2 -A1 "curl.*|.*sh" \
             --include="*.sh" --include="*.md" --exclude-dir=external . > "$temp_file" || true
        if grep -q "curl.*|.*sh" "$temp_file" && \
           ! grep -q -E "(# Note:.*trusted|# Note:.*official|# Note:.*safe)" "$temp_file"; then
          echo "::warning::Potentially unsafe curl|sh patterns found"
        fi
        rm -f "$temp_file"

  # === macOS Testing Environment ===
  test-macos:
    name: macOS Integration Tests
    runs-on: macos-latest
    strategy:
      matrix:
        shell: [zsh, bash]

    steps:
    - name: Checkout repository
      uses: actions/checkout@v5
      with:
        submodules: recursive

    - name: Install Homebrew dependencies
      run: |
        # Install essential tools for testing
        brew install stow shellcheck gnu-sed
        brew install --cask font-fira-code-nerd-font || true

    - name: Test basic setup
      run: |
        set -e
        echo "Testing with ${{ matrix.shell }}"

        # Test basic script syntax
        bash -n bin/setup.sh
        bash -n bin/health-check.sh
        bash -n bin/measure-shell-performance.sh

        # Test stow functionality
        mkdir -p test-home/.config
        cd test-home
        stow -d ../stow -t . zsh || echo "Stow test completed"

        # Test environment detection with the matrix shell
        if [ "${{ matrix.shell }}" = "zsh" ]; then
          export ZSH_ENV_WORK=false
          export ZSH_ENV_PERSONAL=true
          zsh -c "source ../stow/zsh/.config/zsh/environment.zsh || true"
          echo "Environment detection: Work=$ZSH_ENV_WORK, Personal=$ZSH_ENV_PERSONAL"
        else
          echo "Skipping zsh-specific environment test for ${{ matrix.shell }}"
        fi

    - name: Test performance measurement
      run: |
        # Test the performance measurement script
        chmod +x bin/measure-shell-performance.sh
        timeout 60 ./bin/measure-shell-performance.sh 3 zsh || echo "Performance test completed with timeout"

    - name: Test health checks
      run: |
        # Test health check script
        chmod +x bin/health-check.sh
        ./bin/health-check.sh --help
        # Basic health check without full installation
        export DOTFILES_CI_MODE=true
        ./bin/health-check.sh basic || echo "Basic health check completed"

  # === Performance Regression Testing ===
  performance-test:
    name: Performance Regression Tests
    runs-on: macos-latest
    if: github.event_name == 'pull_request'

    steps:
    - name: Checkout base branch
      uses: actions/checkout@v5
      with:
        ref: ${{ github.base_ref }}
        path: base
        submodules: recursive

    - name: Checkout PR branch
      uses: actions/checkout@v5
      with:
        path: pr
        submodules: recursive

    - name: Install testing tools
      run: |
        brew install hyperfine jq bc coreutils

    - name: Performance baseline (base branch)
      working-directory: base
      run: |
        if [ -f "bin/measure-shell-performance.sh" ]; then
          chmod +x bin/measure-shell-performance.sh
          if ! gtimeout 120 ./bin/measure-shell-performance.sh --no-color 10 > ../baseline-performance.log; then
            echo "Performance script failed, skipping detailed analysis"
          fi
        fi

        # Measure basic shell startup
        if ! hyperfine --warmup 3 --runs 10 --export-json ../baseline-hyperfine.json \
          'zsh -c exit'; then
          echo "Baseline hyperfine measurement failed"
        fi

    - name: Performance test (PR branch)
      working-directory: pr
      run: |
        if [ -f "bin/measure-shell-performance.sh" ]; then
          chmod +x bin/measure-shell-performance.sh
          if ! gtimeout 120 ./bin/measure-shell-performance.sh --no-color 10 > ../pr-performance.log; then
            echo "Performance script failed, skipping detailed analysis"
          fi
        fi

        # Measure basic shell startup
        if ! hyperfine --warmup 3 --runs 10 --export-json ../pr-hyperfine.json \
          'zsh -c exit'; then
          echo "PR hyperfine measurement failed"
        fi

    - name: Compare performance
      run: |
        echo "## Performance Comparison" >> performance-report.md
        echo "" >> performance-report.md

        if [ -f "baseline-hyperfine.json" ] && [ -f "pr-hyperfine.json" ]; then
          baseline_mean=$(jq -r '.results[0].mean' baseline-hyperfine.json)
          pr_mean=$(jq -r '.results[0].mean' pr-hyperfine.json)

          echo "- **Baseline**: ${baseline_mean}s" >> performance-report.md
          echo "- **PR**: ${pr_mean}s" >> performance-report.md

          # Calculate percentage change
          change=$(echo "scale=2; ($pr_mean - $baseline_mean) / $baseline_mean * 100" | bc -l || echo "0")
          echo "- **Change**: ${change}%" >> performance-report.md

          if (( $(echo "$change > 20" | bc -l) )); then
            echo "::warning::Performance regression detected: ${change}% slower"
          elif (( $(echo "$change < -10" | bc -l) )); then
            echo "::notice::Performance improvement detected: ${change}% faster"
          fi
        fi

        # Output comparison if measure-shell-performance.sh results exist
        if [ -f "baseline-performance.log" ] && [ -f "pr-performance.log" ]; then
          echo "" >> performance-report.md
          echo "### Detailed Performance Analysis" >> performance-report.md
          echo "" >> performance-report.md
          echo "**Baseline:**" >> performance-report.md
          echo '```' >> performance-report.md
          tail -5 baseline-performance.log >> performance-report.md || true
          echo '```' >> performance-report.md
          echo "" >> performance-report.md
          echo "**PR:**" >> performance-report.md
          echo '```' >> performance-report.md
          tail -5 pr-performance.log >> performance-report.md || true
          echo '```' >> performance-report.md
        fi

        cat performance-report.md

    - name: Comment PR with performance results
      if: github.event_name == 'pull_request'
      uses: actions/github-script@v8.0.0
      with:
        script: |
          const fs = require('fs');
          if (fs.existsSync('performance-report.md')) {
            const report = fs.readFileSync('performance-report.md', 'utf8');
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: '## 🚀 Performance Analysis\n\n' + report
            });
          }

  # === Dependency and Security Scanning ===
  security-scan:
    name: Security & Dependency Scan
    runs-on: ubuntu-latest

    steps:
    - name: Checkout repository
      uses: actions/checkout@v5
      with:
        submodules: recursive

    - name: Run Trivy vulnerability scanner
      uses: aquasecurity/trivy-action@master
      with:
        scan-type: 'fs'
        scan-ref: '.'
        format: 'sarif'
        output: 'trivy-results.sarif'
        severity: 'CRITICAL,HIGH,MEDIUM'

    - name: Upload Trivy scan results to GitHub Security tab
      uses: actions/upload-artifact@v5
      if: always()
      with:
        name: trivy-results
        path: trivy-results.sarif

    - name: Check Raycast extensions for vulnerabilities
      run: |
        for ext_dir in raycast/extensions/*/; do
          if [ -f "$ext_dir/package.json" ]; then
            echo "Scanning $ext_dir for vulnerabilities..."
            cd "$ext_dir"
            npm audit --audit-level=moderate || echo "Audit completed for $ext_dir"
            cd - > /dev/null
          fi
        done

  # === Integration Testing ===
  integration-test:
    name: Integration Tests
    runs-on: macos-latest
    needs: [lint, test-macos]

    steps:
    - name: Checkout repository
      uses: actions/checkout@v5
      with:
        submodules: recursive

    - name: Install dependencies
      run: |
        # Install stow for integration testing
        brew install stow

    - name: Full installation test
      run: |
        # Create test environment
        export DOTFILES_TEST_MODE=true
        export HOMEBREW_NO_AUTO_UPDATE=1

        # Test installation scripts
        bash -n bin/setup.sh
        bash -n bin/setup-stow.sh
        bash -n bin/health-check.sh

        # Test configuration validation
        mkdir -p test-install
        cd test-install

        # Test stow installation with packages that exist
        stow -d ../stow -t . --no-folding zsh bash tmux

        # Test that symlinks were created correctly
        [ -L .zshenv ] && echo "✓ zsh symlink created"
        [ -L .bashrc ] && echo "✓ bash symlink created"
        [ -L .tmux.conf ] && echo "✓ tmux symlink created"

    - name: Test automation scripts
      run: |
        # Test automation scripts exist and are executable
        chmod +x bin/*.sh

        # Test help flags
        ./bin/health-check.sh --help
        ./bin/measure-shell-performance.sh --help
        ./bin/auto-sync.sh --help || echo "auto-sync help completed"

        echo "All automation scripts tested successfully"


  # === Notification and Reporting ===
  notify:
    name: Notify Results
    runs-on: ubuntu-latest
    needs: [lint, test-macos, performance-test, security-scan, integration-test]
    if: always()

    steps:
    - name: Prepare notification
      run: |
        echo "## CI/CD Pipeline Results" > notification.md
        echo "" >> notification.md
        echo "- **Lint**: ${{ needs.lint.result }}" >> notification.md
        echo "- **macOS Tests**: ${{ needs.test-macos.result }}" >> notification.md
        echo "- **Performance**: ${{ needs.performance-test.result }}" >> notification.md
        echo "- **Security Scan**: ${{ needs.security-scan.result }}" >> notification.md
        echo "- **Integration**: ${{ needs.integration-test.result }}" >> notification.md
        echo "" >> notification.md
        echo "Commit: ${{ github.sha }}" >> notification.md
        echo "Branch: ${{ github.ref }}" >> notification.md

        cat notification.md

    - name: Success notification
      if: >
        needs.lint.result == 'success' &&
        needs.test-macos.result == 'success' &&
        needs.security-scan.result == 'success' &&
        needs.integration-test.result == 'success'
      run: |
        echo "::notice::✅ All CI/CD pipeline jobs completed successfully!"

    - name: Failure notification
      if: >
        needs.lint.result == 'failure' ||
        needs.test-macos.result == 'failure' ||
        needs.security-scan.result == 'failure' ||
        needs.integration-test.result == 'failure'
      run: |
        echo "::error::❌ CI/CD pipeline has failures that need attention"
        exit 1
